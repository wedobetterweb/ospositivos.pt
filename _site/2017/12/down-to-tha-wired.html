<!DOCTYPE html>
<html lang="pt"><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="/assets//favicon.ico" rel="icon" type="image/x-icon" /><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>down to tha wired | OS POSITIVOS</title>
<meta name="generator" content="Jekyll v3.8.3" />
<meta property="og:title" content="down to tha wired" />
<meta name="author" content="Os Positivos" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Próximos de final de ano, aquela altura para revisões e listas. Da Wired, esse pasquim do Vale do Silicone, duas peças que valem o registo nas frentes da tecnologia, arte e aquele nosso tópico. I [AI is] producing artificial scenes and sounds that look stunningly close to actual footage of the physical world. Unlike earlier experiments with AI-generated media, these look and sound real. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Da nova realidade: Currently there are two ways to produce audio or video that resembles the real world. The first is to record a moment in time. The second is to leverage human talent to commission a facsimile. Machine learning algorithms now offer a third option, by letting anyone with a modicum of technical knowledge algorithmically remix existing content to generate new material. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Os artsys serão sensíveis a esta em particular: a Adobe é o industry standard na indústria do imaginário visual, sigamos as tendências. The technologies underlying this shift will soon push us into new creative realms At Adobe, machine learning has been a part of the company’s creative products for well over a decade, but only recently has AI become transformative. Adobe’s artificial intelligence platform, Sensei, [is] infusing machine learning into a variety of groundbreaking video, photo, and audio editing tools. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 I am excited about the possibility of new art forms emerging, which I expect will be coming. Photoshop is great at manipulating pixels, but what people are trying to do is manipulate the content that is represented by the pixels. That’s a good thing. When artists no longer waste their time wrangling individual dots on a screen, their productivity increases, and perhaps also their ingenuity. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Produtividade e arte - mas hoje não... Mais ao ponto para resumo e retomar: We will search for new definitions of creativity that extend the umbrella to the output of machines. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 ...ie, onde os artistas vão aos arames e a democratização das &quot;artes&quot;. Sensei’s tools let artists work with concepts, rather than the raw material. &quot;What I like about these technologies is they are democratizing design and style. I’m a technologist—I appreciate beauty and style but can’t produce it worth a damn. So this work makes it available to me. And there’s a joy in making it available to others, so people can play with beauty. Just because we are not gifted on this certain axis doesn’t mean we have to live in a dreary land.&quot; in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 But this boom will have a dark side, too. Some AI-generated content will be used to deceive, kicking off fears of an avalanche of algorithmic fake news. Old debates about whether an image was doctored will give way to new ones about the pedigree of all kinds of content, including text. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Including comics, dizemos nós, e esse é o core do nosso debate do autentico. E seguindo ao darkside: It was just a matter of time before a motivated engineer tried to automate the process [of] generating convincing news articles. But it’s not hard to see how this creative explosion could all go very wrong. Some of the dangers of machine learning: at its worst, scammers and political operatives will deploy machine learning algorithms to generate untold volumes of misinformation. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Afinal, a nossa deixa. Fake photos and videos [spreads fast], the verification process is [slow], the best defense, for now, is raising awareness of what machine learning is capable of. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 OS POSITIVOS: ya welcome. II It’s getting easier for lots of people to interact with each other, either through a company’s platform or through distributed peer-to-peer systems. And to the extent all of these interactions are digitally mediated, they create records. Those records are all really exciting to researchers. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Quando toda a essa informação nos importa. Destaque nosso: Figuring out how human beings do human things is one of the most exciting things that science -psychology, sociology, economics, anthropology- can do. It’s also one of the hardest. Matt Salganik, a sociologist at Princeton, is trying to solve that hard problem. He wants to know how human beings behave and why, especially in a socially mediated world. To do it, Salganik has become a hardcore data nerd. The digital traces everyone now leaves on servers provide inexhaustible fuel for the science of human behavior, he says. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 I converted the book into a series of websites, and anyone could come and read them and annotate them. I was able to collect a tremendous amount of feedback that helped with the book, and I was able to collect a lot of data about how people interacted with the book in the wild. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 &lt;/p&gt; Livros out in tha open... já de si uma consequência de novos meios. Differences between data scientists and social scientists / where do those cultures diverge: Social scientists in the past have generally worked with data that was specifically created for the purposes of research. In the book I call this &quot;custom-made data.&quot; So for example if social scientists wanted to study public opinion, their natural first thought would be to look at a survey like the General Social Survey, done by researchers for other researchers. And data scientists tend to work with &quot;ready-made data,&quot; originally made for one purpose and being repurposed for research. A data scientist’s first stop might be to look at Twitter. What [is] valued in these different communities: for social scientists, it’s often being able to make an empirical statement about some bigger theory. For data scientists, it’s often more to do something neat or interesting or novel with data. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Ética. Desta, entre académicos et tech: No one wants to be unethical, but the ethics of a lot of analog-era social science research has more or less been settled. Generally there’s agreement on what you can and can’t do. Our ability to observe millions of people without consent or awareness, and our ability to enroll people in experiments without consent or awareness, these are new things we can do, and I don’t think we as academics have figured out how to use that power responsibly. A big challenge for us in the digital age is to figure out how to take advantage of these opportunities in a way that’s responsible. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 E porque nada diz &quot;ética&quot; no reino da filosofia como o discurso em diálogo, segue-se um: There’s a lot of opportunity in general in any kinds of transaction records. Facebook and Twitter, a lot of this is data people are intentionally creating, but there’s a big possibility in data more implicitly created. - W: Social sciences are dealing with a crisis that’s about data—reproducibility problems and statistical manipulations that call into question some of the field’s key findings. - MS: I would say the transition from the analog age to the digital age, which is what’s driving a lot of these new sources of data, is also enabling social scientists to have new work practices. It makes it easier for us to share our data and code, and it makes it easier for us to provide access to our research to everyone, not just people who are lucky enough to be at universities with subscriptions to expensive journals. The digital age has the possibility of helping us change and improve our scientific practices in ways that I think people are excited about and starting to embrace. -W: What, specifically, has changed in that transition to the digital age? - MS: Now there’s a lot of data being generated as a byproduct of everyday actions. This is &quot;digital trace data&quot; or &quot;digital exhaust.&quot; It’s often at a much bigger scale, which creates a lot of interesting research opportunities, but it also comes with some problems. The data often has the goals of the company or government baked into it. This is called &quot;algorithmic confounding.&quot; - W: What does that mean? - MS: Learning about human behavior from Facebook data is like learning about human behavior by watching people in a casino. A casino is a highly engineered environment designed to encourage some behavior and discourage other behavior. Facebook is similar. When people look at Facebook they think, &quot;Oh, this is people’s natural behavior.&quot; And that’s not true at all. The goals of the system designer are not the goals of the researcher in many cases. And then there’s access. Facebook and Twitter have enormous amounts of data that are not available to every researcher. If there’s a situation where some researchers have access and others don’t, this can create concerns about reproducibility, the role some companies play in allowing certain projects to go forward and not others, and the role they could play in encouraging certain types of results. The challenge for all of us is to figure out how this data that could be beneficial to scientists and society in general can be made available in ways that would be safe for the people providing the data and safe for the companies E o estado desta arte circa finais de 2017 parece-nos devidamente registada. O takeway: - W: But this science goes way beyond just social media. - MS: My kids, who are 8 and 4, are growing up talking to Alexa. They’re going to interact with the world in a different way than I did. Those kind of psychological impacts will take a while for us to be able to observe and understand, but we’re already starting to see major changes in industry and social relations. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Próximo: os media em revisão." />
<meta property="og:description" content="Próximos de final de ano, aquela altura para revisões e listas. Da Wired, esse pasquim do Vale do Silicone, duas peças que valem o registo nas frentes da tecnologia, arte e aquele nosso tópico. I [AI is] producing artificial scenes and sounds that look stunningly close to actual footage of the physical world. Unlike earlier experiments with AI-generated media, these look and sound real. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Da nova realidade: Currently there are two ways to produce audio or video that resembles the real world. The first is to record a moment in time. The second is to leverage human talent to commission a facsimile. Machine learning algorithms now offer a third option, by letting anyone with a modicum of technical knowledge algorithmically remix existing content to generate new material. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Os artsys serão sensíveis a esta em particular: a Adobe é o industry standard na indústria do imaginário visual, sigamos as tendências. The technologies underlying this shift will soon push us into new creative realms At Adobe, machine learning has been a part of the company’s creative products for well over a decade, but only recently has AI become transformative. Adobe’s artificial intelligence platform, Sensei, [is] infusing machine learning into a variety of groundbreaking video, photo, and audio editing tools. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 I am excited about the possibility of new art forms emerging, which I expect will be coming. Photoshop is great at manipulating pixels, but what people are trying to do is manipulate the content that is represented by the pixels. That’s a good thing. When artists no longer waste their time wrangling individual dots on a screen, their productivity increases, and perhaps also their ingenuity. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Produtividade e arte - mas hoje não... Mais ao ponto para resumo e retomar: We will search for new definitions of creativity that extend the umbrella to the output of machines. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 ...ie, onde os artistas vão aos arames e a democratização das &quot;artes&quot;. Sensei’s tools let artists work with concepts, rather than the raw material. &quot;What I like about these technologies is they are democratizing design and style. I’m a technologist—I appreciate beauty and style but can’t produce it worth a damn. So this work makes it available to me. And there’s a joy in making it available to others, so people can play with beauty. Just because we are not gifted on this certain axis doesn’t mean we have to live in a dreary land.&quot; in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 But this boom will have a dark side, too. Some AI-generated content will be used to deceive, kicking off fears of an avalanche of algorithmic fake news. Old debates about whether an image was doctored will give way to new ones about the pedigree of all kinds of content, including text. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Including comics, dizemos nós, e esse é o core do nosso debate do autentico. E seguindo ao darkside: It was just a matter of time before a motivated engineer tried to automate the process [of] generating convincing news articles. But it’s not hard to see how this creative explosion could all go very wrong. Some of the dangers of machine learning: at its worst, scammers and political operatives will deploy machine learning algorithms to generate untold volumes of misinformation. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Afinal, a nossa deixa. Fake photos and videos [spreads fast], the verification process is [slow], the best defense, for now, is raising awareness of what machine learning is capable of. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 OS POSITIVOS: ya welcome. II It’s getting easier for lots of people to interact with each other, either through a company’s platform or through distributed peer-to-peer systems. And to the extent all of these interactions are digitally mediated, they create records. Those records are all really exciting to researchers. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Quando toda a essa informação nos importa. Destaque nosso: Figuring out how human beings do human things is one of the most exciting things that science -psychology, sociology, economics, anthropology- can do. It’s also one of the hardest. Matt Salganik, a sociologist at Princeton, is trying to solve that hard problem. He wants to know how human beings behave and why, especially in a socially mediated world. To do it, Salganik has become a hardcore data nerd. The digital traces everyone now leaves on servers provide inexhaustible fuel for the science of human behavior, he says. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 I converted the book into a series of websites, and anyone could come and read them and annotate them. I was able to collect a tremendous amount of feedback that helped with the book, and I was able to collect a lot of data about how people interacted with the book in the wild. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 &lt;/p&gt; Livros out in tha open... já de si uma consequência de novos meios. Differences between data scientists and social scientists / where do those cultures diverge: Social scientists in the past have generally worked with data that was specifically created for the purposes of research. In the book I call this &quot;custom-made data.&quot; So for example if social scientists wanted to study public opinion, their natural first thought would be to look at a survey like the General Social Survey, done by researchers for other researchers. And data scientists tend to work with &quot;ready-made data,&quot; originally made for one purpose and being repurposed for research. A data scientist’s first stop might be to look at Twitter. What [is] valued in these different communities: for social scientists, it’s often being able to make an empirical statement about some bigger theory. For data scientists, it’s often more to do something neat or interesting or novel with data. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Ética. Desta, entre académicos et tech: No one wants to be unethical, but the ethics of a lot of analog-era social science research has more or less been settled. Generally there’s agreement on what you can and can’t do. Our ability to observe millions of people without consent or awareness, and our ability to enroll people in experiments without consent or awareness, these are new things we can do, and I don’t think we as academics have figured out how to use that power responsibly. A big challenge for us in the digital age is to figure out how to take advantage of these opportunities in a way that’s responsible. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 E porque nada diz &quot;ética&quot; no reino da filosofia como o discurso em diálogo, segue-se um: There’s a lot of opportunity in general in any kinds of transaction records. Facebook and Twitter, a lot of this is data people are intentionally creating, but there’s a big possibility in data more implicitly created. - W: Social sciences are dealing with a crisis that’s about data—reproducibility problems and statistical manipulations that call into question some of the field’s key findings. - MS: I would say the transition from the analog age to the digital age, which is what’s driving a lot of these new sources of data, is also enabling social scientists to have new work practices. It makes it easier for us to share our data and code, and it makes it easier for us to provide access to our research to everyone, not just people who are lucky enough to be at universities with subscriptions to expensive journals. The digital age has the possibility of helping us change and improve our scientific practices in ways that I think people are excited about and starting to embrace. -W: What, specifically, has changed in that transition to the digital age? - MS: Now there’s a lot of data being generated as a byproduct of everyday actions. This is &quot;digital trace data&quot; or &quot;digital exhaust.&quot; It’s often at a much bigger scale, which creates a lot of interesting research opportunities, but it also comes with some problems. The data often has the goals of the company or government baked into it. This is called &quot;algorithmic confounding.&quot; - W: What does that mean? - MS: Learning about human behavior from Facebook data is like learning about human behavior by watching people in a casino. A casino is a highly engineered environment designed to encourage some behavior and discourage other behavior. Facebook is similar. When people look at Facebook they think, &quot;Oh, this is people’s natural behavior.&quot; And that’s not true at all. The goals of the system designer are not the goals of the researcher in many cases. And then there’s access. Facebook and Twitter have enormous amounts of data that are not available to every researcher. If there’s a situation where some researchers have access and others don’t, this can create concerns about reproducibility, the role some companies play in allowing certain projects to go forward and not others, and the role they could play in encouraging certain types of results. The challenge for all of us is to figure out how this data that could be beneficial to scientists and society in general can be made available in ways that would be safe for the people providing the data and safe for the companies E o estado desta arte circa finais de 2017 parece-nos devidamente registada. O takeway: - W: But this science goes way beyond just social media. - MS: My kids, who are 8 and 4, are growing up talking to Alexa. They’re going to interact with the world in a different way than I did. Those kind of psychological impacts will take a while for us to be able to observe and understand, but we’re already starting to see major changes in industry and social relations. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Próximo: os media em revisão." />
<link rel="canonical" href="http://localhost:4000/2017/12/down-to-tha-wired.html" />
<meta property="og:url" content="http://localhost:4000/2017/12/down-to-tha-wired.html" />
<meta property="og:site_name" content="OS POSITIVOS" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-12-14T14:51:00+00:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","headline":"down to tha wired","dateModified":"2017-12-14T14:51:00+00:00","datePublished":"2017-12-14T14:51:00+00:00","url":"http://localhost:4000/2017/12/down-to-tha-wired.html","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/12/down-to-tha-wired.html"},"author":{"@type":"Person","name":"Os Positivos"},"description":"Próximos de final de ano, aquela altura para revisões e listas. Da Wired, esse pasquim do Vale do Silicone, duas peças que valem o registo nas frentes da tecnologia, arte e aquele nosso tópico. I [AI is] producing artificial scenes and sounds that look stunningly close to actual footage of the physical world. Unlike earlier experiments with AI-generated media, these look and sound real. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Da nova realidade: Currently there are two ways to produce audio or video that resembles the real world. The first is to record a moment in time. The second is to leverage human talent to commission a facsimile. Machine learning algorithms now offer a third option, by letting anyone with a modicum of technical knowledge algorithmically remix existing content to generate new material. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Os artsys serão sensíveis a esta em particular: a Adobe é o industry standard na indústria do imaginário visual, sigamos as tendências. The technologies underlying this shift will soon push us into new creative realms At Adobe, machine learning has been a part of the company’s creative products for well over a decade, but only recently has AI become transformative. Adobe’s artificial intelligence platform, Sensei, [is] infusing machine learning into a variety of groundbreaking video, photo, and audio editing tools. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 I am excited about the possibility of new art forms emerging, which I expect will be coming. Photoshop is great at manipulating pixels, but what people are trying to do is manipulate the content that is represented by the pixels. That’s a good thing. When artists no longer waste their time wrangling individual dots on a screen, their productivity increases, and perhaps also their ingenuity. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Produtividade e arte - mas hoje não... Mais ao ponto para resumo e retomar: We will search for new definitions of creativity that extend the umbrella to the output of machines. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 ...ie, onde os artistas vão aos arames e a democratização das &quot;artes&quot;. Sensei’s tools let artists work with concepts, rather than the raw material. &quot;What I like about these technologies is they are democratizing design and style. I’m a technologist—I appreciate beauty and style but can’t produce it worth a damn. So this work makes it available to me. And there’s a joy in making it available to others, so people can play with beauty. Just because we are not gifted on this certain axis doesn’t mean we have to live in a dreary land.&quot; in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 But this boom will have a dark side, too. Some AI-generated content will be used to deceive, kicking off fears of an avalanche of algorithmic fake news. Old debates about whether an image was doctored will give way to new ones about the pedigree of all kinds of content, including text. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Including comics, dizemos nós, e esse é o core do nosso debate do autentico. E seguindo ao darkside: It was just a matter of time before a motivated engineer tried to automate the process [of] generating convincing news articles. But it’s not hard to see how this creative explosion could all go very wrong. Some of the dangers of machine learning: at its worst, scammers and political operatives will deploy machine learning algorithms to generate untold volumes of misinformation. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 Afinal, a nossa deixa. Fake photos and videos [spreads fast], the verification process is [slow], the best defense, for now, is raising awareness of what machine learning is capable of. in &quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot; 13 dez 2017 OS POSITIVOS: ya welcome. II It’s getting easier for lots of people to interact with each other, either through a company’s platform or through distributed peer-to-peer systems. And to the extent all of these interactions are digitally mediated, they create records. Those records are all really exciting to researchers. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Quando toda a essa informação nos importa. Destaque nosso: Figuring out how human beings do human things is one of the most exciting things that science -psychology, sociology, economics, anthropology- can do. It’s also one of the hardest. Matt Salganik, a sociologist at Princeton, is trying to solve that hard problem. He wants to know how human beings behave and why, especially in a socially mediated world. To do it, Salganik has become a hardcore data nerd. The digital traces everyone now leaves on servers provide inexhaustible fuel for the science of human behavior, he says. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 I converted the book into a series of websites, and anyone could come and read them and annotate them. I was able to collect a tremendous amount of feedback that helped with the book, and I was able to collect a lot of data about how people interacted with the book in the wild. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 &lt;/p&gt; Livros out in tha open... já de si uma consequência de novos meios. Differences between data scientists and social scientists / where do those cultures diverge: Social scientists in the past have generally worked with data that was specifically created for the purposes of research. In the book I call this &quot;custom-made data.&quot; So for example if social scientists wanted to study public opinion, their natural first thought would be to look at a survey like the General Social Survey, done by researchers for other researchers. And data scientists tend to work with &quot;ready-made data,&quot; originally made for one purpose and being repurposed for research. A data scientist’s first stop might be to look at Twitter. What [is] valued in these different communities: for social scientists, it’s often being able to make an empirical statement about some bigger theory. For data scientists, it’s often more to do something neat or interesting or novel with data. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Ética. Desta, entre académicos et tech: No one wants to be unethical, but the ethics of a lot of analog-era social science research has more or less been settled. Generally there’s agreement on what you can and can’t do. Our ability to observe millions of people without consent or awareness, and our ability to enroll people in experiments without consent or awareness, these are new things we can do, and I don’t think we as academics have figured out how to use that power responsibly. A big challenge for us in the digital age is to figure out how to take advantage of these opportunities in a way that’s responsible. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 E porque nada diz &quot;ética&quot; no reino da filosofia como o discurso em diálogo, segue-se um: There’s a lot of opportunity in general in any kinds of transaction records. Facebook and Twitter, a lot of this is data people are intentionally creating, but there’s a big possibility in data more implicitly created. - W: Social sciences are dealing with a crisis that’s about data—reproducibility problems and statistical manipulations that call into question some of the field’s key findings. - MS: I would say the transition from the analog age to the digital age, which is what’s driving a lot of these new sources of data, is also enabling social scientists to have new work practices. It makes it easier for us to share our data and code, and it makes it easier for us to provide access to our research to everyone, not just people who are lucky enough to be at universities with subscriptions to expensive journals. The digital age has the possibility of helping us change and improve our scientific practices in ways that I think people are excited about and starting to embrace. -W: What, specifically, has changed in that transition to the digital age? - MS: Now there’s a lot of data being generated as a byproduct of everyday actions. This is &quot;digital trace data&quot; or &quot;digital exhaust.&quot; It’s often at a much bigger scale, which creates a lot of interesting research opportunities, but it also comes with some problems. The data often has the goals of the company or government baked into it. This is called &quot;algorithmic confounding.&quot; - W: What does that mean? - MS: Learning about human behavior from Facebook data is like learning about human behavior by watching people in a casino. A casino is a highly engineered environment designed to encourage some behavior and discourage other behavior. Facebook is similar. When people look at Facebook they think, &quot;Oh, this is people’s natural behavior.&quot; And that’s not true at all. The goals of the system designer are not the goals of the researcher in many cases. And then there’s access. Facebook and Twitter have enormous amounts of data that are not available to every researcher. If there’s a situation where some researchers have access and others don’t, this can create concerns about reproducibility, the role some companies play in allowing certain projects to go forward and not others, and the role they could play in encouraging certain types of results. The challenge for all of us is to figure out how this data that could be beneficial to scientists and society in general can be made available in ways that would be safe for the people providing the data and safe for the companies E o estado desta arte circa finais de 2017 parece-nos devidamente registada. O takeway: - W: But this science goes way beyond just social media. - MS: My kids, who are 8 and 4, are growing up talking to Alexa. They’re going to interact with the world in a different way than I did. Those kind of psychological impacts will take a while for us to be able to observe and understand, but we’re already starting to see major changes in industry and social relations. in &quot;Psychologists Want in on Social Media&#39;s Big Data Trove&quot; 13 dez 2017 Próximo: os media em revisão.","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css">
    <link rel="stylesheet" href="/assets/uikitgrid.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="OS POSITIVOS" /><link href='https://fonts.googleapis.com/css?family=Permanent+Marker' rel='stylesheet' />
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,700' rel='stylesheet' />
    <link href='https://fonts.googleapis.com/css?family=Sedgwick+Ave+Display' rel='stylesheet' />
</head><body 
        
        >
    
      <header>
    <a href="/">
    <img src="http://localhost:4000/assets/x.png" alt="OS POSITIVOS" width="200" />
    </a>
</header><article class="post">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">down to tha wired</h1>
  </header>

    <div class="coluna">
  <p>Próximos de final de ano, aquela altura para revisões e listas. Da <b><em>Wired</em></b>, esse pasquim do Vale do Silicone, duas peças que valem o registo nas frentes da <b>tecnologia</b>, <b>arte</b> e <em><b>aquele</b></em> nosso tópico.</p>
  <br>
  <h3 class="centre"><small><span class="info">I</span></small></h3>
  <br>
  <div class="info coluna">
    <blockquote>
      <p><b><span class="voice">[AI is]</span> producing artificial scenes and sounds that look stunningly close to actual footage of the physical world. Unlike earlier experiments with AI-generated media, these look and sound</b> <strong>real</strong>.<br>
        <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small></p>
    </blockquote>
  </div>
  <p>Da nova realidade:</p>
  <blockquote>
    <p>Currently there are two ways to produce audio or video that resembles the real world. </p>
    <ul class="lista">
      <li>The first is to record a moment in time. </li>
      <li>The second is to leverage human talent to commission a facsimile. </li>
    </ul>
    <p>Machine learning algorithms now offer a third option, by letting anyone with a modicum of technical knowledge algorithmically remix existing content to generate new material.<br>
      <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small></p>
  </blockquote>
  <p>Os <em>artsys</em> serão sensíveis  a esta em particular: a <b>Adobe</b> é o <em>industry  standard</em> na indústria do imaginário visual, sigamos as tendências.</p>
  <div class="blurb"><i class="bubble"></i> The technologies underlying this shift will soon push us into new creative realms</div>
  <blockquote>
    <p>At Adobe, machine learning has been a part of the company’s creative products for well over a decade, but only recently has AI become transformative. Adobe’s artificial intelligence platform, Sensei, <span class="voice">[is]</span> infusing machine learning into a variety of groundbreaking video, photo, and audio editing tools.<br>
      <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
  </blockquote>
  <div class="blurb"><i class="bubble"></i> I am excited about the possibility of new art forms emerging, which I expect will be coming.</div>
  <blockquote>
    <p>Photoshop is great at manipulating pixels, but what people are trying to do is manipulate the content that is represented by the pixels. That’s a good thing. When artists no longer waste their time wrangling individual dots on a screen, their <strong>productivity increases</strong>, and perhaps also their ingenuity.<br>
      <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
  </blockquote>
  <p>Produtividade e arte - mas <a href="http://www.ospositivos.com/2017/12/smart-work-and-work-smart.html">hoje não</a>... Mais ao ponto para resumo e retomar:</p>
  <div class="info coluna">
    <h3>We will search for new definitions of creativity that extend the umbrella to the output of machines.<br>
      <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small> </h3>
  </div>
  <p>...ie, onde os artistas vão aos arames e a democratização das &quot;artes&quot;.</p>
  <div class="blurb"><i class="bubble"></i> Sensei’s tools let artists work with concepts, rather than the raw material. </div>
  <blockquote>
    <p>&quot;What I like about these technologies is they are democratizing design and style.  I’m a technologist—I appreciate beauty and style but can’t produce it worth a damn. So this work makes it available to me. And there’s a joy in making it available to others, so people can play with beauty. Just because we are not gifted on this certain axis doesn’t mean we have to live in a dreary land.&quot;<br>
      <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small></p>
    <p>But this boom will have a dark side, too. Some AI-generated content will be used to deceive, kicking off fears of an avalanche of algorithmic fake news. Old debates about whether an image was doctored will give way to new ones about the pedigree of all kinds of content, including text.<br>
      <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
  </blockquote>
  <p><em><b>Including comics</b></em>, dizemos nós, e esse é o core do nosso debate do <strong>autentico</strong>. <br>
    E seguindo ao <em>darkside</em>:</p>
  <div class="blurb"><i class="bubble"></i> It was just a matter of time before a motivated engineer tried to automate the process <span class="voice">[of]</span> generating convincing news articles. </div>
  <blockquote>
    <p>But it’s not hard to see how this creative explosion could all go very wrong. Some of the dangers of machine learning: at its worst, scammers and political operatives will <b>deploy machine learning algorithms to generate untold volumes of misinformation</b>.<br>
      <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
  </blockquote>
  <p>Afinal, a nossa deixa.</p>
  <blockquote>
    <p>Fake photos and videos <span class="voice">[spreads fast]</span>, the verification process is <span class="voice">[slow</span>], the best defense, for now, <b>is raising awareness of what machine learning is capable of</b>.<br>
      <small>in <a href="https://www.wired.com/story/future-of-artificial-intelligence-2018/" target="_blank"><em>&quot;Artificial Intelligence Is Killing the Uncanny Valley and Our Grasp on Reality&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
  </blockquote>
  <p><b>OS POSITIVOS</b>:<em> ya welcome.</em></p>
  <br>
  <h3 class="centre"><small><span class="info">II</span></small></h3>
  <br>
  <div class="info coluna">
    <blockquote>
      <p><b>It’s getting easier for lots of people to interact with each other, either through a company’s platform or through distributed peer-to-peer systems. And to the extent all of these interactions are digitally mediated, they create records. Those records are all really exciting to researchers. </b><br>
        <small>in <a href="https://www.wired.com/story/the-traces-of-your-digital-life-could-upend-social-science/" target="_blank"><em>&quot;Psychologists Want in on Social Media's Big Data Trove&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
    </blockquote>
  </div>
  <p>Quando toda a essa informação nos importa. Destaque nosso:</p>
  <blockquote>
    <p>Figuring out how human beings do human things is one of the most exciting things that science -<b>psychology, sociology, economics, anthropology</b>- can do. It’s also one of the hardest. Matt Salganik, a sociologist at Princeton, is trying to solve that hard problem. He wants to know how human beings behave and why, especially in a socially mediated world. To do it, Salganik has become a hardcore data nerd. The digital traces everyone now leaves on servers provide inexhaustible fuel for the science of human behavior, he says.<br>
      <small> in <a href="https://www.wired.com/story/the-traces-of-your-digital-life-could-upend-social-science/" target="_blank"><em>&quot;Psychologists Want in on Social Media's Big Data Trove&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
  </blockquote>
  <div class="coluna smallish">
    <blockquote> <small><em>I converted the book into a series of websites, and anyone could come and read them and annotate them. I was able to collect a tremendous amount of feedback that helped with the book, and I was able to collect a lot of data about how people interacted with the book in the wild.</em></small><br>
      <small> in <a href="https://www.wired.com/story/the-traces-of-your-digital-life-could-upend-social-science/" target="_blank"><em>&quot;Psychologists Want in on Social Media's Big Data Trove&quot;</em></a> <sup>13 dez 2017</sup></small>
      </p>
    </blockquote>
    <p> Livros <a href="http://www.ospositivos.com/2017/11/self-publishing-for-fun-and-profit.html"><em>out in tha open</em></a>... já de si uma consequência de novos meios.</p>
  </div>
  <blockquote>
    <p>Differences between data scientists and social scientists / where do those cultures diverge:</p>
  </blockquote>
  <ul>
    <li> Social scientists in the past have generally worked with data that was specifically created for the purposes of research. In the book I call this &quot;custom-made data.&quot; So for example if social scientists wanted to study public opinion, their natural first thought would be to look at a survey like the General Social Survey, done by researchers for other researchers. </li>
    <li>And data scientists tend to work with &quot;ready-made data,&quot; originally made for one purpose and being repurposed for research.  A data scientist’s first stop might be to look at Twitter.</li>
  </ul>
  <blockquote>
    <p>What <span class="voice">[is]</span> valued in these different communities: for social scientists, it’s often being able to make an empirical statement about some bigger theory. For data scientists, it’s often more to do something neat or interesting or novel with data.<br>
      <small> in <a href="https://www.wired.com/story/the-traces-of-your-digital-life-could-upend-social-science/" target="_blank"><em>&quot;Psychologists Want in on Social Media's Big Data Trove&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
  </blockquote>
  <p><a href="http://www.ospositivos.com/2017/11/cultura-critica.html">Ética</a>. Desta, entre académicos <em>et tech</em>:</p>
  <blockquote>
    <p><b>No one wants to be unethical</b>, but the ethics of a lot of analog-era social science research has more or less been settled. Generally there’s agreement on what you can and can’t do.</p>
    <p> Our ability to observe millions of people without consent or awareness, and our ability to enroll people in experiments without consent or awareness, these are new things we can do, and I don’t think we as academics have figured out how to use that power responsibly.<br>
      A big challenge for us in the digital age is to figure out how to take advantage of these opportunities in a way that’s responsible.<br>
      <small> in <a href="https://www.wired.com/story/the-traces-of-your-digital-life-could-upend-social-science/" target="_blank"><em>&quot;Psychologists Want in on Social Media's Big Data Trove&quot;</em></a> <sup>13 dez 2017</sup></small> </p>
  </blockquote>
  <p>E porque nada diz "ética" no reino da filosofia como o discurso em diálogo, segue-se um:</p>
  <div class="blurb"><i class="bubble"></i> There’s a lot of opportunity in general in any kinds of transaction records. Facebook and Twitter, a lot of this is data people are intentionally creating, but there’s a big possibility in data more implicitly created. </div>
  <blockquote>
    <p><small>- W:</small><b> Social sciences are dealing with a crisis that’s about data—reproducibility problems and statistical manipulations that call into question some of the field’s key findings.</b><br>
      <small>- MS:</small> I would say the transition from the analog age to the digital age, which is what’s driving a lot of these new sources of data, is also enabling social scientists to have new work practices. It makes it easier for us to share our data and code, and it makes it easier for us to provide access to our research to everyone, not just people who are lucky enough to be at universities with subscriptions to expensive journals. The digital age has the possibility of helping us change and improve our scientific practices in ways that I think people are excited about and starting to embrace.<br>
      <small>-W:</small><b> What, specifically, has changed in that transition to the digital age?</b><br>
      <small>- MS:</small> Now there’s a lot of data being generated as a byproduct of everyday actions. This is &quot;digital trace data&quot; or &quot;digital exhaust.&quot; It’s often at a much bigger scale, which creates a lot of interesting research opportunities, but it also comes with some problems. The data often has the goals of the company or government baked into it. This is called &quot;algorithmic confounding.&quot;<br>
      <small>- W:</small> <b>What does that mean?</b><br>
      <small>- MS: </small> Learning about human behavior from Facebook data is like learning about human behavior by watching people in a casino. A casino is a highly engineered environment designed to encourage some behavior and discourage other behavior. Facebook is similar. When people look at Facebook they think, &quot;Oh, this is people’s natural behavior.&quot; And that’s not true at all. The goals of the system designer are not the goals of the researcher in many cases.<br>
      And then there’s access. Facebook and Twitter have enormous amounts of data that are not available to every researcher. If there’s a situation where some researchers have access and others don’t, this can create concerns about reproducibility, the role some companies play in allowing certain projects to go forward and not others, and the role they could play in encouraging certain types of results. The challenge for all of us is to figure out how this data that could be beneficial to scientists and society in general can be made available in ways that would be safe for the people providing the data and safe for the companies</p>
  </blockquote>
  <p>E o estado desta arte <em>circa</em> finais de 2017 parece-nos devidamente registada. <br>
  O <em>takeway</em>:</p>
  <div class="info coluna">
    <blockquote>
      <p><small>- W:</small> <b>But this science goes way beyond just social media</b>.<br>
        <small>- MS:</small> My kids, who are 8 and 4, are growing up talking to Alexa. They’re going to interact with the world in a different way than I did. Those kind of psychological impacts will take a while for us to be able to observe and understand, but<strong> we’re already starting to see major changes in industry and social relations</strong>.<br>
        <small> in <a href="https://www.wired.com/story/the-traces-of-your-digital-life-could-upend-social-science/" target="_blank"><em>&quot;Psychologists Want in on Social Media's Big Data Trove&quot;</em></a> <sup>13 dez 2017</sup></small> <br>
      </p>
    </blockquote>
  </div>
  <p>Próximo: os media em revisão.</p>

<div class="espaco-topo centre">
<img border="0" src="https://1.bp.blogspot.com/-S5MSjbB7nps/WjKP0YYvkvI/AAAAAAAAPhY/j1bFgOOgAlYi3wt_XEIM404LgYcAM0p3wCLcBGAs/s1600/make-a-list.jpg" /></div>

</div>

<h2 id="next"><a href="http://www.ospositivos.com/2017/12/revisto.html">revistos</a></h2>


  <a class="u-url" href="/2017/12/down-to-tha-wired.html" hidden></a>
</article><footer>
    
    fanzine do contra com cultura: uma outra cena de <a href="https://www.ospositivos.com/2018/05/previously-xiii.html">banda desenhada</a> desalinhada desdenhada de propaganda punk veggie anti-nazi com humor &amp; depressão q/b
    
    <div id="mc_embed_signup">
        <form action="https://ospositivos.us2.list-manage.com/subscribe/post?u=fb6c5fa7a252e2f3f153d3e6b&amp;id=f1d1e2deb3" class="validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="novalidate" style="margin:0 auto; max-width:100%;" target="_blank">
            <input class="required email" id="mce-EMAIL" name="EMAIL" value="" type="email">
            <input id="mc-embedded-subscribe" name="subscribe" style="border-radius:0;" value="Subscrever newsletter" type="submit">
    
            <div class="clear" id="mce-responses">
                <div class="response" id="mce-error-response" style="display:none">
                </div>
                <div class="response" id="mce-success-response" style="display:none">
                </div>
            </div>
            
            <div style="position: absolute; left: -5000px;">
                <input name="b_fb6c5fa7a252e2f3f153d3e6b_e75182a646" value="" type="text">
            </div>
        </form>
    </div>
    
    <span style="text-transform: uppercase;letter-spacing: 3px;">comix<span style="color:red">@</span>ospositivos.com</span>
    
</footer>
</body>

</html>